<!DOCTYPE html>
<html>

<link rel="stylesheet" href="/app/styling.css">
<meta name="viewport" content="width=device-width, initial-scale=1.0">

<style>
    .table-title {
        margin-top: 50px;
        text-align: center;
    }


    .content-table {
        border-collapse: collapse;
        margin: 25px 0;
        font-size: 0.9em;
        min-width: 400px;
        border-radius: 5px;
        overflow: hidden;
        box-shadow: 0 10px 20px rgba(0, 0, 0, 0.15);
        margin-left: auto;
        margin-right: auto;
    }

    .content-table thead tr {
        background-color: #009879;
        color: #ffffff;
        text-align: left;
        font-weight: bold;
    }

    .content-table th,
    .content-table td {
        padding: 12px 15px;
    }

    .content-table tbody tr {
        border-bottom: thin solid #dddddd;
    }

    .content-table tbody tr:nth-of-type(even) {
        background-color: #f3f3f3;
    }

    .content-table tbody tr:last-of-type {
        border-bottom: 2px solid #009879;
    }
</style>


<head>
    <title>Commercially Available LLM Models</title>
</head>

<body>
    <h1>General Information for Currently available LLM Models</h1>
    <h1 class="table-title">Commercially Available LLM Models</h1>
    <h3>The following table provides you with general information on the LLM's that are currently available 
        on the market, their context window size, input and output submission costs, and where applicable the 
        knowledge base date that the information is based off.</h3>
        <p>The context or context window is the amount of information that's taken as an input for a query by
            the user. The length of the context window is based on token length. Each token is equivalent to four
            characters or 3/4 of a word in English, with 100 words being equivalent to 75 words.
            
            Consider the following; smaller input lengths will result in the LLM having less input to process, 
            which results in faster input generation.
        </p>

    <table class="content-table">
        <thead>
            <tr>
                <th>Company</th>
                <th>Model Name</th>
                <th>Context</th>
                <th>Input ($)</th>
                <th>Output ($)</th>
                <th>Knowledge Base</th>
            </tr>
        </thead>
        <tbody>
            <!-- Injected LLM model dataset here -->
        </tbody>
    </table>
</body>

</html>